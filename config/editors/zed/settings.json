// Zed settings
//
// For information on how to configure Zed, see the Zed
// documentation: https://zed.dev/docs/configuring-zed
//
// To see all of Zed's default settings without changing your
// custom settings, run `zed: open default settings` from the
// command palette (cmd-shift-p / ctrl-shift-p)
{
  "tabs": {
    "git_status": true,
  },
  "relative_line_numbers": "disabled",
  "agent_servers": {
    "claude": {
      "default_model": "svc/glm-4.7",
      "favorite_models": [],
      "default_config_options": {},
      "favorite_config_option_values": {},
    },
    "gemini": {
      "ignore_system_version": false,
    },
    "OpenCode": {
      "favorite_models": [
        "wolf-ai/svc/glm-4.7",
        "wolf-ai/svc/kimi-k2",
        "wolf-ai/glm-4.7",
        "wolf-ai/ack-dev",
        "google/antigravity-gemini-3-pro-high",
        "google/antigravity-gemini-3-pro-low",
        "google/antigravity-gemini-3-flash",
        "google/antigravity-gemini-3-pro",
        "google/antigravity-claude-sonnet-4-5-thinking"
      ],
      "type": "custom",
      "command": "opencode",
      "args": ["acp"],
      "env": { "HTTPS_PROXY": "http://127.0.0.1:6152", "OPENCODE_EXPERIMENTAL_LSP_TY": "1" },
    },
  },
  "git_panel": {
    "tree_view": true,
    "collapse_untracked_diff": true,
  },
  "session": {
    "trust_all_worktrees": true,
  },
  "vim_mode": true,
  "icon_theme": "Zed (Default)",
  "features": {
    "edit_prediction_provider": "copilot",
  },
  "ssh_connections": [
    {
      "host": "ack-h20",
      "args": [],
      "projects": [
        {
          "paths": ["/home/yuchen.liu/src/iroot-llm"],
        },
        {
          "paths": ["/home/yuchen.liu/src/sglang"],
        },
        {
          "paths": ["/home/yuchen.liu/src/zed"],
        },
      ],
    },
  ],
  "context_servers": {
    "local-mcp-server": {
      "command": "npx",
      "args": ["-y", "@mcp_router/cli@latest", "connect"],
      "env": { "MCPR_TOKEN": "mcpr_5NEN_XhnOaZ3dUmq28RgjvguA07yK6AH" },
    },
  },
  "agent": {
    "message_editor_min_lines": 5,
    "show_turn_stats": true,
    "use_modifier_to_send": true,
    "default_profile": "write",
    "always_allow_tool_actions": true,
    "default_model": {
      "provider": "Wolf-Ack",
      "model": "svc/gpt-oss-120b",
    },
    "model_parameters": [],
    "profiles": {
      "write": {
        "name": "Write",
        "enable_all_context_servers": true,
        "tools": {
          "thinking": false, // üëà Êîπ‰∏∫ false Âç≥ÂèØÁ¶ÅÁî®
          "web_search": true,
        },
      },
      "ask": {
        "name": "Ask",
        "enable_all_context_servers": true,
        "tools": {
          "thinking": false, // üëà ‰πüÂèØ‰ª•Á¶ÅÁî® ask profile ÁöÑ thinking
        },
      },
    },
  },
  "language_models": {
    "anthropic": {
      "api_url": "http://localhost:4000",
      "available_models": [
        {
          "name": "svc/glm-4.7",
          "display_name": "GLM 4.7",
          "max_tokens": 200000,
          "max_output_tokens": 32000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
        {
          "name": "svc/kimi-k2",
          "display_name": "GLM 4.7 Dev",
          "max_tokens": 200000,
          "max_output_tokens": 32000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
      ],
    },
    "openai_compatible": {
      "Wolf-Ack-Dev": {
        "api_url": "http://localhost:4000/v1",
        "available_models": [
          {
            "name": "local_gpt_proxy",
            "max_tokens": 202752,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
              "thinking_mode": "preserved",
            },
          },
        ],
      },
      "Wolf-Dev": {
        "api_url": "http://arena-serve-sglang-l20x-gpt-oss-120b.yilab-lmt.ai.rootcloud.info/v1",
        "available_models": [
          {
            "name": "gpt-oss-120b-direct",
            "max_tokens": 128000,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
              "thinking_mode": "preserved",
            },
          },
        ],
      },
      "Wolf-Ack": {
        "api_url": "http://api.ai.rootcloud.info/v1",
        "available_models": [
          {
            "name": "svc/glm-4.7",
            "max_tokens": 200000,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
              "thinking_mode": "preserved",
            },
          },
          {
            "name": "svc/kimi-k2",
            "max_tokens": 200000,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
              "thinking_mode": "preserved",
            },
          },
          {
            "name": "svc/gpt-oss-120b",
            "max_tokens": 120000,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": false,
              "thinking_mode": "preserved",
            },
          },
        ],
      },
    },
  },
  "telemetry": {
    "diagnostics": false,
    "metrics": false,
  },
  "terminal": {
    "detect_venv": {
      "on": {
        "directories": [".env", "env", ".venv", "venv"],
        "activate_script": "default",
      },
    },
    "shell": {
      "program": "fish",
    },
    "font_family": "CaskaydiaCove Nerd Font",
    "font_fallbacks": ["Sarasa Mono SC Nerd Font", "Symbols Nerd Font", "Menlo", "Monaco", "Courier New"],
  },
  "proxy": "http://127.0.0.1:6152",
  "base_keymap": "VSCode",
  "minimap": {
    "show": "never",
  },
  "autosave": "on_focus_change",
  "buffer_font_fallbacks": ["Sarasa Mono SC Nerd Font", "Symbols Nerd Font", "Menlo", "Monaco", "Courier New"],
  "buffer_font_family": "CaskaydiaCove Nerd Font",
  "file_types": {
    "cython": ["*.pyx", "*.pyd", "*.pyx.in", "*.pyx", "*.pyd", "*.pyx.in"],
  },
  "preferred_line_length": 160,
  "soft_wrap": "editor_width",
  "ui_font_size": 16,
  "buffer_font_size": 15,
  "theme": {
    "mode": "dark",
    "light": "Gruvbox Light",
    "dark": "Gruvbox ish Dark Hard",
  },
  "languages": {
    "Python": {
      "preferred_line_length": 160,
      "soft_wrap": "prefer_line",
      "language_servers": [
        // Disable basedpyright and enable ty, and otherwise
        // use the default configuration.
        "ty",
        "!basedpyright",
        "...",
      ],
    },
  },
}
