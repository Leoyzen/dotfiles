// Zed settings
//
// For information on how to configure Zed, see the Zed
// documentation: https://zed.dev/docs/configuring-zed
//
// To see all of Zed's default settings without changing your
// custom settings, run `zed: open default settings` from the
// command palette (cmd-shift-p / ctrl-shift-p)
{
  "inlay_hints": {
    "enabled": true,
  },
  "helix_mode": true,
  "tabs": {
    "git_status": true,
  },
  "relative_line_numbers": "disabled",
  "agent_servers": {
    "claude": {
      "default_model": "svc/glm-4.7",
      "favorite_models": [],
      "default_config_options": {},
      "favorite_config_option_values": {},
    },
    "gemini": {
      "ignore_system_version": false,
    },
    "OpenCode": {
      "favorite_models": [
        "wolf-ai/svc/glm-4.7",
        "wolf-ai/svc/kimi-k2",
        "wolf-ai/glm-4.7",
        "wolf-ai/ack-dev",
        "google/antigravity-gemini-3-pro-high",
        "google/antigravity-gemini-3-pro-low",
        "google/antigravity-gemini-3-flash",
        "google/antigravity-gemini-3-pro",
        "google/antigravity-claude-sonnet-4-5-thinking",
        "google/antigravity-claude-opus-4-5-thinking",
        "google/antigravity-claude-sonnet-4-5",
      ],
      "type": "custom",
      "command": "opencode",
      "args": ["acp"],
      "env": {
        "HTTPS_PROXY": "http://127.0.0.1:6152",
        "OPENCODE_EXPERIMENTAL_LSP_TY": "1",
        "OPENCODE_CLIENT": "acp",
        "OPENCODE_MODEL": "svc/glm-4.7",
        "OPENCODE_GEMINI_PRO_MODEL": "google/antigravity-gemini-3-pro",
        "OPENCODE_GEMINI_FLASH_MODEL": "google/antigravity-gemini-3-flash",
        "OPENCODE_CLAUDE_MODEL": "google/antigravity-claude-sonnet-4-5-thinking",
      },
    },
    "Agent-Pool": {
      "type": "custom",
      "command": "uv",
      "env": {
        "UV_PROJECT": "/Users/yuchen.liu/src/yilab/iroot-llm/packages/xeno-agent",
        "LOG_LEVEL": "DEBUG",
        "LOGFIRE_IGNORE_NO_CONFIG": "1",
        "OPENAI_API_BASE": "http://127.0.0.1:4000/v1",
        "OPENAI_API_KEY": "sk-81tG2fae63ORELlKPYbzBw",
        "OPENAI_MODEL_NAME": "svc/glm-4.7",
      },
      "args": [
        "run",
        "agentpool",
        "serve-acp",
        "/Users/yuchen.liu/src/yilab/iroot-llm/packages/xeno-agent/config/diag-agent.yaml",
        "--agent",
        "fault_expert",
        "--subagent-display-mode",
        "inline",
        "--show-messages",
        "--debug-commands",
        "--debug-messages",
        "--debug-file",
        "/tmp/agentpool.log",
        // "--log-level",
        // "DEBUG",
      ],
    },
    "Xeno-Agent": {
      "type": "custom",
      "command": "uv",
      "args": [
        "run",
        "xeno-agent",
        "serve",
        "--config-path",
        "/Users/yuchen.liu/src/yilab/iroot-llm/packages/xeno-agent/config/diag-agent.yaml",
        // "--config-path",
        // "/Users/yuchen.liu/src/yilab/iroot-llm/packages/xeno-agent/config",
        // "--log-file",
        // "/tmp/xeno-agent.log",
      ],
      "env": { "UV_PROJECT": "/Users/yuchen.liu/src/yilab/iroot-llm/packages/xeno-agent" },
    },
  },
  "git_panel": {
    "tree_view": true,
    "collapse_untracked_diff": true,
  },
  "session": {
    "trust_all_worktrees": true,
  },
  "vim_mode": true,
  "icon_theme": "Zed (Default)",
  "features": {
    "edit_prediction_provider": "copilot",
  },
  "ssh_connections": [
    {
      "host": "ack-h20",
      "args": [],
      "projects": [
        {
          "paths": ["/home/yuchen.liu/src/iroot-llm"],
        },
        {
          "paths": ["/home/yuchen.liu/src/sglang"],
        },
        {
          "paths": ["/home/yuchen.liu/src/zed"],
        },
      ],
    },
  ],
  "context_servers": {
    "local-mcp-server": {
      "command": "npx",
      "args": ["-y", "@mcp_router/cli@latest", "connect"],
      "env": { "MCPR_TOKEN": "mcpr_5NEN_XhnOaZ3dUmq28RgjvguA07yK6AH" },
    },
  },
  "agent": {
    "favorite_models": [
      {
        "provider": "anthropic",
        "model": "claude-opus-4-5-thinking",
      },
      {
        "provider": "anthropic",
        "model": "gemini-3-pro-high",
      },
      {
        "provider": "anthropic",
        "model": "gemini-3-flash",
      },
    ],
    "message_editor_min_lines": 5,
    "show_turn_stats": true,
    "use_modifier_to_send": true,
    "default_profile": "write",
    "always_allow_tool_actions": true,
    "default_model": {
      "provider": "Wolf-Ack",
      "model": "svc/glm-4.7",
    },
    "model_parameters": [],
    "profiles": {
      "write": {
        "name": "Write",
        "enable_all_context_servers": true,
        "tools": {
          "thinking": false, // üëà Êîπ‰∏∫ false Âç≥ÂèØÁ¶ÅÁî®
          "web_search": true,
        },
      },
      "ask": {
        "name": "Ask",
        "enable_all_context_servers": true,
        "tools": {
          "thinking": false, // üëà ‰πüÂèØ‰ª•Á¶ÅÁî® ask profile ÁöÑ thinking
        },
      },
    },
  },
  "language_models": {
    "anthropic": {
      "api_url": "https://api.kimi.com/coding/v1",
      "available_models": [
        {
          "name": "kimi-for-coding",
          "max_tokens": 262144,
          "max_output_tokens": 32000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
        {
          "name": "gemini-3-flash",
          "display_name": "Gemini 3 Flash(AG)",
          "max_tokens": 1000000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
        {
          "name": "gemini-3-pro-high",
          "display_name": "Gemini 3 Pro(High, AG)",
          "max_tokens": 1000000,
          "max_output_tokens": 64000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
        {
          "name": "claude-sonnet-4-5",
          "display_name": "Claude Sonnet 4.5(AG)",
          "max_tokens": 2000000,
          "max_output_tokens": 64000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
        {
          "name": "claude-opus-4-5-thinking",
          "display_name": "Claude Opus 4.5(Think, AG)",
          "max_tokens": 2000000,
          "max_output_tokens": 64000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
        {
          "name": "claude-sonnet-4-5-thinking",
          "display_name": "Claude Sonnet 4.5(Think, AG)",
          "max_tokens": 2000000,
          "max_output_tokens": 64000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
        {
          "name": "claude-opus-4-5-thinking",
          "display_name": "Claude Opus 4.5(Think, AG)",
          "max_tokens": 2000000,
          "max_output_tokens": 64000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 10000,
          },
        },
      ],
    },
    "openai_compatible": {
      "Kimi-Code": {
        "api_url": "https://api.kimi.com/coding/v1",
        "available_models": [
          {
            "name": "kimi-for-coding",
            "max_tokens": 202752,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": true,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
            },
          },
        ],
      },
      "Wolf-Ack-Dev": {
        "api_url": "http://localhost:4000/v1",
        "available_models": [
          {
            "name": "local_gpt_proxy",
            "max_tokens": 202752,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
            },
          },
        ],
      },
      "Wolf-Dev": {
        "api_url": "http://arena-serve-sglang-l20x-gpt-oss-120b.yilab-lmt.ai.rootcloud.info/v1",
        "available_models": [
          {
            "name": "gpt-oss-120b-direct",
            "max_tokens": 128000,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
              "thinking_mode": "preserved",
            },
          },
        ],
      },
      "Wolf-Ack": {
        "api_url": "http://api.ai.rootcloud.info/v1",
        "available_models": [
          {
            "name": "svc/glm-4.7",
            "max_tokens": 200000,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
              "thinking_mode": "preserved",
            },
          },
          {
            "name": "svc/kimi-k2",
            "max_tokens": 200000,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": true,
              "thinking_mode": "preserved",
            },
          },
          {
            "name": "svc/gpt-oss-120b",
            "max_tokens": 120000,
            "max_output_tokens": 32000,
            "max_completion_tokens": 32000,
            "capabilities": {
              "tools": true,
              "images": false,
              "parallel_tool_calls": true,
              "prompt_cache_key": false,
              "chat_completions": false,
              "thinking_mode": "preserved",
            },
          },
        ],
      },
    },
  },
  "telemetry": {
    "diagnostics": false,
    "metrics": false,
  },
  "terminal": {
    "copy_on_select": true,
    "detect_venv": {
      "on": {
        "directories": [".env", "env", ".venv", "venv"],
        "activate_script": "fish",
      },
    },
    "shell": {
      "program": "fish",
    },
    "font_family": "CaskaydiaCove Nerd Font",
    "font_fallbacks": ["Sarasa Mono SC Nerd Font", "Symbols Nerd Font", "Menlo", "Monaco", "Courier New"],
  },
  "proxy": "http://127.0.0.1:6152",
  "base_keymap": "VSCode",
  "minimap": {
    "show": "auto",
  },
  "autosave": "on_focus_change",
  "buffer_font_fallbacks": ["Sarasa Mono SC Nerd Font", "Symbols Nerd Font", "Menlo", "Monaco", "Courier New"],
  "buffer_font_family": "CaskaydiaCove Nerd Font",
  "file_types": {
    "cython": ["*.pyx", "*.pyd", "*.pyx.in", "*.pyx", "*.pyd", "*.pyx.in"],
  },
  "preferred_line_length": 160,
  "soft_wrap": "editor_width",
  "ui_font_size": 16,
  "buffer_font_size": 15,
  "theme": {
    "mode": "dark",
    "light": "Gruvbox Light",
    "dark": "Gruvbox Crisp Highest Contrast",
  },
  "languages": {
    "Python": {
      "preferred_line_length": 160,
      "soft_wrap": "prefer_line",
      "language_servers": [
        // Disable basedpyright and enable ty, and otherwise
        // use the default configuration.
        "ty",
        "!basedpyright",
        "...",
      ],
    },
  },
  "lsp": { "ruff": { "binary": { "ignore_system_version": false } } },
}
